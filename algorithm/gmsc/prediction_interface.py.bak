#Filename:	gmsc.py
#Author:	Wang Yongjie
#Email:		yongjie.wang@ntu.edu.sg
#Date:		Sen 12 Jul 2021 10:43:57 

import torch
import sys
import copy
import random
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import accuracy_score
from torch.utils.data import TensorDataset, DataLoader

def create_model(input_len):
    model = nn.Sequential(
            nn.Linear(input_len, 20),
            nn.ReLU(),
            #nn.Dropout(0.2),
            nn.Linear(20, 10),
            nn.ReLU(),
            nn.Linear(10, 1),
            nn.Sigmoid(),
            )
    return model

def train(model, train_loader, optimizer, criterion, device):
    epoch_loss = 0
    prediction = []
    label = []
    model.train()

    for batch_idx, (data, target) in enumerate(train_loader):

        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        preds = torch.round(output)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item() * len(target)
        label.extend(target.tolist())
        prediction.extend(preds.reshape(-1).tolist())

    acc = accuracy_score(prediction, label)
    return epoch_loss / len(train_loader), acc


def test(model, test_loader, criterion, device):

    epoch_loss = 0
    prediction = []
    label = []
    model.eval()
    with torch.no_grad():
        for _, (data, target) in enumerate(test_loader):
            data, target = data.to(device), target.to(device)
            output = model(data)
            preds = torch.round(output)
            loss = criterion(output, target)
            epoch_loss += loss.item() * len(target)
            label.extend(target.tolist())
            prediction.extend(preds.tolist())
    
    prediction = np.array(prediction)
    label = np.array(label)
    acc = accuracy_score(prediction, label)

    return epoch_loss / len(test_loader), acc

if __name__ == "__main__":
    
    batch_size = 128
    epoches = 500

    x_query, y_query = np.load("../../data/GMSC/X_query.npy"), np.load("../../data/GMSC_V1/y_query.npy")
    x_test, y_test = np.load("../../data/GMSC_V1/X_test.npy"), np.load("../../data/GMSC_V1/y_test.npy")

    scaler = MinMaxScaler()
    x_query = scaler.fit_transform(x_query)
    x_test_ = scaler.transform(x_test)

    a = list(range(len(x_query)))
    length = int(sys.argv[1])

    if length == 0:
        length = len(a)

    acc_list = []

    for i in range(30):
        print(i)
        random.shuffle(a)
        idx = a[0:length]
        query_sx, query_sy = x_query[idx], y_query[idx]
    
        query_tensor = TensorDataset(torch.from_numpy(query_sx), torch.from_numpy(query_sy))
        test_tensor = TensorDataset(torch.from_numpy(x_test_), torch.from_numpy(y_test))

        query_loader = DataLoader(query_tensor, batch_size = batch_size)
        test_loader = DataLoader(test_tensor, batch_size = batch_size)

        model = create_model(x_query.shape[1])
        device = torch.device("cpu")

        criterion = nn.BCELoss()
        model = model.to(device)
        criterion = criterion.to(device)
        optimizer = optim.Adam(model.parameters(), lr = 0.005)

        best_model = None
        best_acc = -float('inf')

        for epoch in range(epoches):
            train_loss, train_acc = train(model, query_loader, optimizer, criterion, device)
            if epoch % 50 == 0:
                print(f'Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')
        
        test_loss, test_acc = test(model, test_loader, criterion, device)
        print(f'Test acc: {test_acc:.4f}')
        acc_list.append(np.round(test_acc, 3))

    print(acc_list)
    print(np.round(np.mean(acc_list), 3), np.round(np.std(acc_list), 3))
