{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yongjie/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/yongjie/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(\"synthetic_train.csv\").to_numpy().astype(np.float32)\n",
    "dquery = pd.read_csv(\"synthetic_query.csv\").to_numpy().astype(np.float32)\n",
    "# dval = pd.read_csv(\"synthetic_val.csv\").to_numpy().astype(np.float32)\n",
    "dtest = pd.read_csv(\"synthetic_test.csv\").to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = dtrain[:, 0:2], dtrain[:, 2:3]\n",
    "# val_x, val_y = dval[:, 0:2], dval[:, 2:3]\n",
    "query_x, query_y = dquery[:, 0:2], dquery[:, 2:3]\n",
    "test_x, test_y = dtest[:, 0:2], dtest[:, 2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "# val_x = scaler.transform(val_x)\n",
    "query_x = scaler.transform(query_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "Query = TensorDataset(torch.from_numpy(query_x), torch.from_numpy(query_y))\n",
    "Test = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(Train, batch_size  = 128)\n",
    "query_loader = DataLoader(Query, batch_size = 128)\n",
    "test_loader = DataLoader(Test, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    prediction = []\n",
    "    label = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(iterator):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        preds = torch.round(output)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * len(target)\n",
    "        label.extend(target.tolist())\n",
    "        prediction.extend(preds.reshape(-1).tolist())\n",
    "\n",
    "    acc = accuracy_score(label, prediction)\n",
    "    f1 = f1_score(label, prediction)\n",
    "\n",
    "    return epoch_loss / len(iterator.dataset), acc, f1\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    label = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(iterator):\n",
    "\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            preds = torch.round(output)\n",
    "            loss = criterion(output, target)\n",
    "            epoch_loss += loss.item() * len(target)\n",
    "            label.extend(target.tolist())\n",
    "            prediction.extend(preds.reshape(-1).tolist())\n",
    "            \n",
    "    acc = accuracy_score(label, prediction)\n",
    "    f1 = f1_score(label, prediction)\n",
    "\n",
    "    return epoch_loss / len(iterator.dataset), acc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.6622 | Train Acc: 0.6143 | Train F1: 0.4357\n",
      "Epoch: 0 | Val. Loss: 0.7162 |  Val. Acc: 0.4499 |  Val. F1: 0.0000\n",
      "Epoch: 1 | Train Loss: 0.5788 | Train Acc: 0.8084 | Train F1: 0.7784\n",
      "Epoch: 1 | Val. Loss: 0.9060 |  Val. Acc: 0.4587 |  Val. F1: 0.0316\n",
      "Epoch: 2 | Train Loss: 0.4424 | Train Acc: 0.8698 | Train F1: 0.8607\n",
      "Epoch: 2 | Val. Loss: 1.3006 |  Val. Acc: 0.5462 |  Val. F1: 0.2979\n",
      "Epoch: 3 | Train Loss: 0.3195 | Train Acc: 0.8855 | Train F1: 0.8841\n",
      "Epoch: 3 | Val. Loss: 1.5022 |  Val. Acc: 0.6090 |  Val. F1: 0.4488\n",
      "Epoch: 4 | Train Loss: 0.2560 | Train Acc: 0.8894 | Train F1: 0.8898\n",
      "Epoch: 4 | Val. Loss: 1.5869 |  Val. Acc: 0.6454 |  Val. F1: 0.5244\n",
      "Epoch: 5 | Train Loss: 0.2364 | Train Acc: 0.8899 | Train F1: 0.8905\n",
      "Epoch: 5 | Val. Loss: 1.6950 |  Val. Acc: 0.6562 |  Val. F1: 0.5455\n",
      "Epoch: 6 | Train Loss: 0.2283 | Train Acc: 0.8894 | Train F1: 0.8902\n",
      "Epoch: 6 | Val. Loss: 1.8517 |  Val. Acc: 0.6473 |  Val. F1: 0.5283\n",
      "Epoch: 7 | Train Loss: 0.2233 | Train Acc: 0.8914 | Train F1: 0.8924\n",
      "Epoch: 7 | Val. Loss: 1.9370 |  Val. Acc: 0.6444 |  Val. F1: 0.5224\n",
      "Epoch: 8 | Train Loss: 0.2192 | Train Acc: 0.8924 | Train F1: 0.8932\n",
      "Epoch: 8 | Val. Loss: 2.0346 |  Val. Acc: 0.6395 |  Val. F1: 0.5126\n",
      "Epoch: 9 | Train Loss: 0.2152 | Train Acc: 0.8963 | Train F1: 0.8970\n",
      "Epoch: 9 | Val. Loss: 2.1489 |  Val. Acc: 0.6316 |  Val. F1: 0.4966\n",
      "Epoch: 10 | Train Loss: 0.2114 | Train Acc: 0.8988 | Train F1: 0.8991\n",
      "Epoch: 10 | Val. Loss: 2.2249 |  Val. Acc: 0.6277 |  Val. F1: 0.4885\n",
      "Epoch: 11 | Train Loss: 0.2078 | Train Acc: 0.9032 | Train F1: 0.9032\n",
      "Epoch: 11 | Val. Loss: 2.3074 |  Val. Acc: 0.6198 |  Val. F1: 0.4720\n",
      "Epoch: 12 | Train Loss: 0.2046 | Train Acc: 0.9061 | Train F1: 0.9062\n",
      "Epoch: 12 | Val. Loss: 2.3886 |  Val. Acc: 0.6169 |  Val. F1: 0.4658\n",
      "Epoch: 13 | Train Loss: 0.2018 | Train Acc: 0.9096 | Train F1: 0.9094\n",
      "Epoch: 13 | Val. Loss: 2.4545 |  Val. Acc: 0.6130 |  Val. F1: 0.4573\n",
      "Epoch: 14 | Train Loss: 0.1994 | Train Acc: 0.9101 | Train F1: 0.9098\n",
      "Epoch: 14 | Val. Loss: 2.5211 |  Val. Acc: 0.6081 |  Val. F1: 0.4466\n",
      "Epoch: 15 | Train Loss: 0.1972 | Train Acc: 0.9120 | Train F1: 0.9117\n",
      "Epoch: 15 | Val. Loss: 2.5794 |  Val. Acc: 0.6051 |  Val. F1: 0.4401\n",
      "Epoch: 16 | Train Loss: 0.1953 | Train Acc: 0.9145 | Train F1: 0.9142\n",
      "Epoch: 16 | Val. Loss: 2.6300 |  Val. Acc: 0.6031 |  Val. F1: 0.4358\n",
      "Epoch: 17 | Train Loss: 0.1937 | Train Acc: 0.9160 | Train F1: 0.9156\n",
      "Epoch: 17 | Val. Loss: 2.6674 |  Val. Acc: 0.5982 |  Val. F1: 0.4248\n",
      "Epoch: 18 | Train Loss: 0.1921 | Train Acc: 0.9160 | Train F1: 0.9156\n",
      "Epoch: 18 | Val. Loss: 2.6991 |  Val. Acc: 0.5953 |  Val. F1: 0.4181\n",
      "Epoch: 19 | Train Loss: 0.1908 | Train Acc: 0.9170 | Train F1: 0.9166\n",
      "Epoch: 19 | Val. Loss: 2.7142 |  Val. Acc: 0.5914 |  Val. F1: 0.4091\n",
      "Epoch: 20 | Train Loss: 0.1896 | Train Acc: 0.9165 | Train F1: 0.9162\n",
      "Epoch: 20 | Val. Loss: 2.7428 |  Val. Acc: 0.5894 |  Val. F1: 0.4046\n",
      "Epoch: 21 | Train Loss: 0.1886 | Train Acc: 0.9170 | Train F1: 0.9167\n",
      "Epoch: 21 | Val. Loss: 2.7679 |  Val. Acc: 0.5864 |  Val. F1: 0.3977\n",
      "Epoch: 22 | Train Loss: 0.1877 | Train Acc: 0.9170 | Train F1: 0.9167\n",
      "Epoch: 22 | Val. Loss: 2.7846 |  Val. Acc: 0.5855 |  Val. F1: 0.3954\n",
      "Epoch: 23 | Train Loss: 0.1867 | Train Acc: 0.9174 | Train F1: 0.9172\n",
      "Epoch: 23 | Val. Loss: 2.7939 |  Val. Acc: 0.5835 |  Val. F1: 0.3908\n",
      "Epoch: 24 | Train Loss: 0.1860 | Train Acc: 0.9174 | Train F1: 0.9172\n",
      "Epoch: 24 | Val. Loss: 2.8064 |  Val. Acc: 0.5806 |  Val. F1: 0.3838\n",
      "Epoch: 25 | Train Loss: 0.1851 | Train Acc: 0.9170 | Train F1: 0.9166\n",
      "Epoch: 25 | Val. Loss: 2.8095 |  Val. Acc: 0.5806 |  Val. F1: 0.3838\n",
      "Epoch: 26 | Train Loss: 0.1844 | Train Acc: 0.9189 | Train F1: 0.9187\n",
      "Epoch: 26 | Val. Loss: 2.8227 |  Val. Acc: 0.5786 |  Val. F1: 0.3792\n",
      "Epoch: 27 | Train Loss: 0.1836 | Train Acc: 0.9179 | Train F1: 0.9177\n",
      "Epoch: 27 | Val. Loss: 2.8131 |  Val. Acc: 0.5786 |  Val. F1: 0.3792\n",
      "Epoch: 28 | Train Loss: 0.1832 | Train Acc: 0.9189 | Train F1: 0.9187\n",
      "Epoch: 28 | Val. Loss: 2.8260 |  Val. Acc: 0.5776 |  Val. F1: 0.3768\n",
      "Epoch: 29 | Train Loss: 0.1824 | Train Acc: 0.9189 | Train F1: 0.9187\n",
      "Epoch: 29 | Val. Loss: 2.8077 |  Val. Acc: 0.5776 |  Val. F1: 0.3768\n",
      "Epoch: 30 | Train Loss: 0.1821 | Train Acc: 0.9199 | Train F1: 0.9197\n",
      "Epoch: 30 | Val. Loss: 2.8420 |  Val. Acc: 0.5766 |  Val. F1: 0.3745\n",
      "Epoch: 31 | Train Loss: 0.1814 | Train Acc: 0.9194 | Train F1: 0.9191\n",
      "Epoch: 31 | Val. Loss: 2.8225 |  Val. Acc: 0.5776 |  Val. F1: 0.3768\n",
      "Epoch: 32 | Train Loss: 0.1810 | Train Acc: 0.9204 | Train F1: 0.9202\n",
      "Epoch: 32 | Val. Loss: 2.8472 |  Val. Acc: 0.5766 |  Val. F1: 0.3745\n",
      "Epoch: 33 | Train Loss: 0.1803 | Train Acc: 0.9204 | Train F1: 0.9202\n",
      "Epoch: 33 | Val. Loss: 2.8213 |  Val. Acc: 0.5766 |  Val. F1: 0.3745\n",
      "Epoch: 34 | Train Loss: 0.1801 | Train Acc: 0.9204 | Train F1: 0.9202\n",
      "Epoch: 34 | Val. Loss: 2.8513 |  Val. Acc: 0.5747 |  Val. F1: 0.3697\n",
      "Epoch: 35 | Train Loss: 0.1796 | Train Acc: 0.9199 | Train F1: 0.9197\n",
      "Epoch: 35 | Val. Loss: 2.8260 |  Val. Acc: 0.5756 |  Val. F1: 0.3721\n",
      "Epoch: 36 | Train Loss: 0.1792 | Train Acc: 0.9204 | Train F1: 0.9203\n",
      "Epoch: 36 | Val. Loss: 2.8572 |  Val. Acc: 0.5727 |  Val. F1: 0.3650\n",
      "Epoch: 37 | Train Loss: 0.1789 | Train Acc: 0.9204 | Train F1: 0.9203\n",
      "Epoch: 37 | Val. Loss: 2.8336 |  Val. Acc: 0.5737 |  Val. F1: 0.3673\n",
      "Epoch: 38 | Train Loss: 0.1781 | Train Acc: 0.9214 | Train F1: 0.9213\n",
      "Epoch: 38 | Val. Loss: 2.8339 |  Val. Acc: 0.5737 |  Val. F1: 0.3673\n",
      "Epoch: 39 | Train Loss: 0.1782 | Train Acc: 0.9209 | Train F1: 0.9207\n",
      "Epoch: 39 | Val. Loss: 2.8459 |  Val. Acc: 0.5727 |  Val. F1: 0.3650\n",
      "Epoch: 40 | Train Loss: 0.1776 | Train Acc: 0.9199 | Train F1: 0.9197\n",
      "Epoch: 40 | Val. Loss: 2.8285 |  Val. Acc: 0.5737 |  Val. F1: 0.3673\n",
      "Epoch: 41 | Train Loss: 0.1773 | Train Acc: 0.9219 | Train F1: 0.9218\n",
      "Epoch: 41 | Val. Loss: 2.8545 |  Val. Acc: 0.5717 |  Val. F1: 0.3626\n",
      "Epoch: 42 | Train Loss: 0.1771 | Train Acc: 0.9204 | Train F1: 0.9203\n",
      "Epoch: 42 | Val. Loss: 2.8389 |  Val. Acc: 0.5727 |  Val. F1: 0.3650\n",
      "Epoch: 43 | Train Loss: 0.1766 | Train Acc: 0.9219 | Train F1: 0.9218\n",
      "Epoch: 43 | Val. Loss: 2.8495 |  Val. Acc: 0.5707 |  Val. F1: 0.3602\n",
      "Epoch: 44 | Train Loss: 0.1766 | Train Acc: 0.9209 | Train F1: 0.9208\n",
      "Epoch: 44 | Val. Loss: 2.8563 |  Val. Acc: 0.5707 |  Val. F1: 0.3602\n",
      "Epoch: 45 | Train Loss: 0.1759 | Train Acc: 0.9189 | Train F1: 0.9188\n",
      "Epoch: 45 | Val. Loss: 2.8376 |  Val. Acc: 0.5717 |  Val. F1: 0.3626\n",
      "Epoch: 46 | Train Loss: 0.1761 | Train Acc: 0.9224 | Train F1: 0.9223\n",
      "Epoch: 46 | Val. Loss: 2.8623 |  Val. Acc: 0.5697 |  Val. F1: 0.3578\n",
      "Epoch: 47 | Train Loss: 0.1756 | Train Acc: 0.9199 | Train F1: 0.9198\n",
      "Epoch: 47 | Val. Loss: 2.8471 |  Val. Acc: 0.5707 |  Val. F1: 0.3602\n",
      "Epoch: 48 | Train Loss: 0.1754 | Train Acc: 0.9224 | Train F1: 0.9222\n",
      "Epoch: 48 | Val. Loss: 2.8644 |  Val. Acc: 0.5697 |  Val. F1: 0.3578\n",
      "Epoch: 49 | Train Loss: 0.1751 | Train Acc: 0.9229 | Train F1: 0.9229\n",
      "Epoch: 49 | Val. Loss: 2.8659 |  Val. Acc: 0.5697 |  Val. F1: 0.3578\n",
      "Epoch: 50 | Train Loss: 0.1749 | Train Acc: 0.9219 | Train F1: 0.9218\n",
      "Epoch: 50 | Val. Loss: 2.8658 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 51 | Train Loss: 0.1747 | Train Acc: 0.9224 | Train F1: 0.9223\n",
      "Epoch: 51 | Val. Loss: 2.8692 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 52 | Train Loss: 0.1746 | Train Acc: 0.9229 | Train F1: 0.9229\n",
      "Epoch: 52 | Val. Loss: 2.8777 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 53 | Train Loss: 0.1743 | Train Acc: 0.9209 | Train F1: 0.9209\n",
      "Epoch: 53 | Val. Loss: 2.8775 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 54 | Train Loss: 0.1744 | Train Acc: 0.9229 | Train F1: 0.9229\n",
      "Epoch: 54 | Val. Loss: 2.8796 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 55 | Train Loss: 0.1738 | Train Acc: 0.9214 | Train F1: 0.9214\n",
      "Epoch: 55 | Val. Loss: 2.8779 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 56 | Train Loss: 0.1739 | Train Acc: 0.9229 | Train F1: 0.9228\n",
      "Epoch: 56 | Val. Loss: 2.8816 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 57 | Train Loss: 0.1736 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 57 | Val. Loss: 2.8920 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 58 | Train Loss: 0.1735 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 58 | Val. Loss: 2.8887 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n",
      "Epoch: 59 | Train Loss: 0.1735 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 59 | Val. Loss: 2.8994 |  Val. Acc: 0.5678 |  Val. F1: 0.3529\n",
      "Epoch: 60 | Train Loss: 0.1728 | Train Acc: 0.9214 | Train F1: 0.9214\n",
      "Epoch: 60 | Val. Loss: 2.8915 |  Val. Acc: 0.5688 |  Val. F1: 0.3554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61 | Train Loss: 0.1731 | Train Acc: 0.9233 | Train F1: 0.9234\n",
      "Epoch: 61 | Val. Loss: 2.8948 |  Val. Acc: 0.5678 |  Val. F1: 0.3529\n",
      "Epoch: 62 | Train Loss: 0.1730 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 62 | Val. Loss: 2.8964 |  Val. Acc: 0.5678 |  Val. F1: 0.3529\n",
      "Epoch: 63 | Train Loss: 0.1728 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 63 | Val. Loss: 2.9080 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 64 | Train Loss: 0.1724 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 64 | Val. Loss: 2.9121 |  Val. Acc: 0.5678 |  Val. F1: 0.3529\n",
      "Epoch: 65 | Train Loss: 0.1726 | Train Acc: 0.9229 | Train F1: 0.9229\n",
      "Epoch: 65 | Val. Loss: 2.9204 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 66 | Train Loss: 0.1725 | Train Acc: 0.9214 | Train F1: 0.9215\n",
      "Epoch: 66 | Val. Loss: 2.9192 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 67 | Train Loss: 0.1723 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 67 | Val. Loss: 2.9205 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 68 | Train Loss: 0.1722 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 68 | Val. Loss: 2.9202 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 69 | Train Loss: 0.1716 | Train Acc: 0.9214 | Train F1: 0.9216\n",
      "Epoch: 69 | Val. Loss: 2.9143 |  Val. Acc: 0.5678 |  Val. F1: 0.3529\n",
      "Epoch: 70 | Train Loss: 0.1718 | Train Acc: 0.9224 | Train F1: 0.9224\n",
      "Epoch: 70 | Val. Loss: 2.9170 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 71 | Train Loss: 0.1719 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 71 | Val. Loss: 2.9479 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 72 | Train Loss: 0.1718 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 72 | Val. Loss: 2.9477 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 73 | Train Loss: 0.1716 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 73 | Val. Loss: 2.9508 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 74 | Train Loss: 0.1717 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 74 | Val. Loss: 2.9431 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 75 | Train Loss: 0.1709 | Train Acc: 0.9219 | Train F1: 0.9220\n",
      "Epoch: 75 | Val. Loss: 2.9295 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 76 | Train Loss: 0.1712 | Train Acc: 0.9229 | Train F1: 0.9229\n",
      "Epoch: 76 | Val. Loss: 2.9260 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 77 | Train Loss: 0.1711 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 77 | Val. Loss: 2.9677 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 78 | Train Loss: 0.1713 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 78 | Val. Loss: 2.9682 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 79 | Train Loss: 0.1712 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 79 | Val. Loss: 2.9705 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 80 | Train Loss: 0.1709 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 80 | Val. Loss: 2.9711 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 81 | Train Loss: 0.1706 | Train Acc: 0.9219 | Train F1: 0.9219\n",
      "Epoch: 81 | Val. Loss: 2.9618 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 82 | Train Loss: 0.1705 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 82 | Val. Loss: 2.9638 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 83 | Train Loss: 0.1705 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 83 | Val. Loss: 2.9876 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 84 | Train Loss: 0.1705 | Train Acc: 0.9233 | Train F1: 0.9235\n",
      "Epoch: 84 | Val. Loss: 2.9898 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 85 | Train Loss: 0.1706 | Train Acc: 0.9233 | Train F1: 0.9235\n",
      "Epoch: 85 | Val. Loss: 2.9967 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 86 | Train Loss: 0.1702 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 86 | Val. Loss: 2.9857 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 87 | Train Loss: 0.1701 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 87 | Val. Loss: 2.9918 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 88 | Train Loss: 0.1699 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 88 | Val. Loss: 2.9857 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 89 | Train Loss: 0.1699 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 89 | Val. Loss: 2.9964 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 90 | Train Loss: 0.1698 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 90 | Val. Loss: 2.9954 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 91 | Train Loss: 0.1697 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 91 | Val. Loss: 3.0059 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 92 | Train Loss: 0.1696 | Train Acc: 0.9233 | Train F1: 0.9235\n",
      "Epoch: 92 | Val. Loss: 3.0043 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 93 | Train Loss: 0.1695 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 93 | Val. Loss: 2.9972 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 94 | Train Loss: 0.1695 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 94 | Val. Loss: 3.0355 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 95 | Train Loss: 0.1694 | Train Acc: 0.9224 | Train F1: 0.9227\n",
      "Epoch: 95 | Val. Loss: 3.0288 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 96 | Train Loss: 0.1694 | Train Acc: 0.9229 | Train F1: 0.9230\n",
      "Epoch: 96 | Val. Loss: 3.0199 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 97 | Train Loss: 0.1692 | Train Acc: 0.9224 | Train F1: 0.9225\n",
      "Epoch: 97 | Val. Loss: 3.0356 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 98 | Train Loss: 0.1690 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 98 | Val. Loss: 3.0220 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 99 | Train Loss: 0.1689 | Train Acc: 0.9233 | Train F1: 0.9235\n",
      "Epoch: 99 | Val. Loss: 3.0249 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 100 | Train Loss: 0.1688 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 100 | Val. Loss: 3.0324 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 101 | Train Loss: 0.1687 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 101 | Val. Loss: 3.0359 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 102 | Train Loss: 0.1687 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 102 | Val. Loss: 3.0390 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 103 | Train Loss: 0.1686 | Train Acc: 0.9229 | Train F1: 0.9231\n",
      "Epoch: 103 | Val. Loss: 3.0359 |  Val. Acc: 0.5648 |  Val. F1: 0.3456\n",
      "Epoch: 104 | Train Loss: 0.1686 | Train Acc: 0.9229 | Train F1: 0.9231\n",
      "Epoch: 104 | Val. Loss: 3.0559 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 105 | Train Loss: 0.1685 | Train Acc: 0.9233 | Train F1: 0.9235\n",
      "Epoch: 105 | Val. Loss: 3.0733 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 106 | Train Loss: 0.1684 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 106 | Val. Loss: 3.0717 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 107 | Train Loss: 0.1682 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 107 | Val. Loss: 3.0857 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 108 | Train Loss: 0.1682 | Train Acc: 0.9219 | Train F1: 0.9222\n",
      "Epoch: 108 | Val. Loss: 3.1036 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 109 | Train Loss: 0.1683 | Train Acc: 0.9229 | Train F1: 0.9231\n",
      "Epoch: 109 | Val. Loss: 3.1104 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 110 | Train Loss: 0.1681 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 110 | Val. Loss: 3.1585 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 111 | Train Loss: 0.1681 | Train Acc: 0.9229 | Train F1: 0.9232\n",
      "Epoch: 111 | Val. Loss: 3.1631 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 112 | Train Loss: 0.1681 | Train Acc: 0.9224 | Train F1: 0.9226\n",
      "Epoch: 112 | Val. Loss: 3.1763 |  Val. Acc: 0.5629 |  Val. F1: 0.3407\n",
      "Epoch: 113 | Train Loss: 0.1679 | Train Acc: 0.9224 | Train F1: 0.9227\n",
      "Epoch: 113 | Val. Loss: 3.2342 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 114 | Train Loss: 0.1680 | Train Acc: 0.9224 | Train F1: 0.9227\n",
      "Epoch: 114 | Val. Loss: 3.2412 |  Val. Acc: 0.5629 |  Val. F1: 0.3407\n",
      "Epoch: 115 | Train Loss: 0.1679 | Train Acc: 0.9229 | Train F1: 0.9232\n",
      "Epoch: 115 | Val. Loss: 3.2763 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 116 | Train Loss: 0.1676 | Train Acc: 0.9224 | Train F1: 0.9228\n",
      "Epoch: 116 | Val. Loss: 3.3359 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 117 | Train Loss: 0.1675 | Train Acc: 0.9229 | Train F1: 0.9233\n",
      "Epoch: 117 | Val. Loss: 3.3683 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 118 | Train Loss: 0.1672 | Train Acc: 0.9224 | Train F1: 0.9229\n",
      "Epoch: 118 | Val. Loss: 3.4298 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 119 | Train Loss: 0.1670 | Train Acc: 0.9224 | Train F1: 0.9229\n",
      "Epoch: 119 | Val. Loss: 3.4899 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 120 | Train Loss: 0.1668 | Train Acc: 0.9229 | Train F1: 0.9233\n",
      "Epoch: 120 | Val. Loss: 3.5524 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 | Train Loss: 0.1667 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 121 | Val. Loss: 3.6520 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 122 | Train Loss: 0.1665 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 122 | Val. Loss: 3.8190 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 123 | Train Loss: 0.1672 | Train Acc: 0.9219 | Train F1: 0.9224\n",
      "Epoch: 123 | Val. Loss: 3.8401 |  Val. Acc: 0.5580 |  Val. F1: 0.3284\n",
      "Epoch: 124 | Train Loss: 0.1675 | Train Acc: 0.9229 | Train F1: 0.9233\n",
      "Epoch: 124 | Val. Loss: 3.8493 |  Val. Acc: 0.5580 |  Val. F1: 0.3284\n",
      "Epoch: 125 | Train Loss: 0.1672 | Train Acc: 0.9224 | Train F1: 0.9230\n",
      "Epoch: 125 | Val. Loss: 3.8664 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 126 | Train Loss: 0.1671 | Train Acc: 0.9229 | Train F1: 0.9234\n",
      "Epoch: 126 | Val. Loss: 3.8693 |  Val. Acc: 0.5589 |  Val. F1: 0.3308\n",
      "Epoch: 127 | Train Loss: 0.1668 | Train Acc: 0.9233 | Train F1: 0.9239\n",
      "Epoch: 127 | Val. Loss: 3.8983 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 128 | Train Loss: 0.1668 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 128 | Val. Loss: 3.9160 |  Val. Acc: 0.5589 |  Val. F1: 0.3308\n",
      "Epoch: 129 | Train Loss: 0.1664 | Train Acc: 0.9238 | Train F1: 0.9244\n",
      "Epoch: 129 | Val. Loss: 3.8981 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 130 | Train Loss: 0.1666 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 130 | Val. Loss: 3.8300 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 131 | Train Loss: 0.1663 | Train Acc: 0.9238 | Train F1: 0.9244\n",
      "Epoch: 131 | Val. Loss: 3.9768 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 132 | Train Loss: 0.1664 | Train Acc: 0.9229 | Train F1: 0.9235\n",
      "Epoch: 132 | Val. Loss: 3.9101 |  Val. Acc: 0.5609 |  Val. F1: 0.3358\n",
      "Epoch: 133 | Train Loss: 0.1661 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 133 | Val. Loss: 3.8955 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 134 | Train Loss: 0.1659 | Train Acc: 0.9238 | Train F1: 0.9245\n",
      "Epoch: 134 | Val. Loss: 3.8911 |  Val. Acc: 0.5629 |  Val. F1: 0.3407\n",
      "Epoch: 135 | Train Loss: 0.1661 | Train Acc: 0.9219 | Train F1: 0.9225\n",
      "Epoch: 135 | Val. Loss: 3.8436 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 136 | Train Loss: 0.1659 | Train Acc: 0.9238 | Train F1: 0.9244\n",
      "Epoch: 136 | Val. Loss: 3.9426 |  Val. Acc: 0.5609 |  Val. F1: 0.3358\n",
      "Epoch: 137 | Train Loss: 0.1660 | Train Acc: 0.9229 | Train F1: 0.9235\n",
      "Epoch: 137 | Val. Loss: 3.9503 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 138 | Train Loss: 0.1657 | Train Acc: 0.9243 | Train F1: 0.9250\n",
      "Epoch: 138 | Val. Loss: 3.9778 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 139 | Train Loss: 0.1658 | Train Acc: 0.9214 | Train F1: 0.9220\n",
      "Epoch: 139 | Val. Loss: 3.9216 |  Val. Acc: 0.5599 |  Val. F1: 0.3333\n",
      "Epoch: 140 | Train Loss: 0.1656 | Train Acc: 0.9243 | Train F1: 0.9250\n",
      "Epoch: 140 | Val. Loss: 3.9214 |  Val. Acc: 0.5629 |  Val. F1: 0.3407\n",
      "Epoch: 141 | Train Loss: 0.1654 | Train Acc: 0.9224 | Train F1: 0.9230\n",
      "Epoch: 141 | Val. Loss: 3.9112 |  Val. Acc: 0.5619 |  Val. F1: 0.3383\n",
      "Epoch: 142 | Train Loss: 0.1653 | Train Acc: 0.9238 | Train F1: 0.9245\n",
      "Epoch: 142 | Val. Loss: 3.8879 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 143 | Train Loss: 0.1652 | Train Acc: 0.9233 | Train F1: 0.9239\n",
      "Epoch: 143 | Val. Loss: 3.8759 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 144 | Train Loss: 0.1652 | Train Acc: 0.9229 | Train F1: 0.9235\n",
      "Epoch: 144 | Val. Loss: 3.9475 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 145 | Train Loss: 0.1651 | Train Acc: 0.9238 | Train F1: 0.9245\n",
      "Epoch: 145 | Val. Loss: 3.9399 |  Val. Acc: 0.5658 |  Val. F1: 0.3481\n",
      "Epoch: 146 | Train Loss: 0.1651 | Train Acc: 0.9214 | Train F1: 0.9220\n",
      "Epoch: 146 | Val. Loss: 3.8998 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 147 | Train Loss: 0.1649 | Train Acc: 0.9229 | Train F1: 0.9235\n",
      "Epoch: 147 | Val. Loss: 3.9650 |  Val. Acc: 0.5639 |  Val. F1: 0.3432\n",
      "Epoch: 148 | Train Loss: 0.1656 | Train Acc: 0.9233 | Train F1: 0.9240\n",
      "Epoch: 148 | Val. Loss: 3.8571 |  Val. Acc: 0.5629 |  Val. F1: 0.3407\n",
      "Epoch: 149 | Train Loss: 0.1642 | Train Acc: 0.9243 | Train F1: 0.9248\n",
      "Epoch: 149 | Val. Loss: 3.9050 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 150 | Train Loss: 0.1645 | Train Acc: 0.9229 | Train F1: 0.9235\n",
      "Epoch: 150 | Val. Loss: 3.7663 |  Val. Acc: 0.5668 |  Val. F1: 0.3505\n",
      "Epoch: 151 | Train Loss: 0.1630 | Train Acc: 0.9248 | Train F1: 0.9253\n",
      "Epoch: 151 | Val. Loss: 3.7835 |  Val. Acc: 0.5707 |  Val. F1: 0.3602\n",
      "Epoch: 152 | Train Loss: 0.1617 | Train Acc: 0.9243 | Train F1: 0.9248\n",
      "Epoch: 152 | Val. Loss: 3.7800 |  Val. Acc: 0.5737 |  Val. F1: 0.3673\n",
      "Epoch: 153 | Train Loss: 0.1603 | Train Acc: 0.9258 | Train F1: 0.9263\n",
      "Epoch: 153 | Val. Loss: 3.6746 |  Val. Acc: 0.5786 |  Val. F1: 0.3792\n",
      "Epoch: 154 | Train Loss: 0.1580 | Train Acc: 0.9258 | Train F1: 0.9262\n",
      "Epoch: 154 | Val. Loss: 3.5382 |  Val. Acc: 0.5884 |  Val. F1: 0.4023\n",
      "Epoch: 155 | Train Loss: 0.1555 | Train Acc: 0.9263 | Train F1: 0.9267\n",
      "Epoch: 155 | Val. Loss: 3.4289 |  Val. Acc: 0.6002 |  Val. F1: 0.4292\n",
      "Epoch: 156 | Train Loss: 0.1526 | Train Acc: 0.9297 | Train F1: 0.9301\n",
      "Epoch: 156 | Val. Loss: 3.3090 |  Val. Acc: 0.6130 |  Val. F1: 0.4573\n",
      "Epoch: 157 | Train Loss: 0.1487 | Train Acc: 0.9302 | Train F1: 0.9306\n",
      "Epoch: 157 | Val. Loss: 2.9485 |  Val. Acc: 0.6316 |  Val. F1: 0.4966\n",
      "Epoch: 158 | Train Loss: 0.1441 | Train Acc: 0.9337 | Train F1: 0.9338\n",
      "Epoch: 158 | Val. Loss: 2.8384 |  Val. Acc: 0.6640 |  Val. F1: 0.5604\n",
      "Epoch: 159 | Train Loss: 0.1400 | Train Acc: 0.9351 | Train F1: 0.9352\n",
      "Epoch: 159 | Val. Loss: 2.7556 |  Val. Acc: 0.6778 |  Val. F1: 0.5859\n",
      "Epoch: 160 | Train Loss: 0.1354 | Train Acc: 0.9376 | Train F1: 0.9377\n",
      "Epoch: 160 | Val. Loss: 2.4434 |  Val. Acc: 0.7024 |  Val. F1: 0.6291\n",
      "Epoch: 161 | Train Loss: 0.1295 | Train Acc: 0.9391 | Train F1: 0.9392\n",
      "Epoch: 161 | Val. Loss: 2.3144 |  Val. Acc: 0.7358 |  Val. F1: 0.6839\n",
      "Epoch: 162 | Train Loss: 0.1243 | Train Acc: 0.9415 | Train F1: 0.9416\n",
      "Epoch: 162 | Val. Loss: 2.3732 |  Val. Acc: 0.7475 |  Val. F1: 0.7022\n",
      "Epoch: 163 | Train Loss: 0.1197 | Train Acc: 0.9455 | Train F1: 0.9457\n",
      "Epoch: 163 | Val. Loss: 2.1335 |  Val. Acc: 0.7652 |  Val. F1: 0.7287\n",
      "Epoch: 164 | Train Loss: 0.1149 | Train Acc: 0.9489 | Train F1: 0.9490\n",
      "Epoch: 164 | Val. Loss: 1.9918 |  Val. Acc: 0.7809 |  Val. F1: 0.7519\n",
      "Epoch: 165 | Train Loss: 0.1100 | Train Acc: 0.9518 | Train F1: 0.9521\n",
      "Epoch: 165 | Val. Loss: 1.9128 |  Val. Acc: 0.7888 |  Val. F1: 0.7630\n",
      "Epoch: 166 | Train Loss: 0.1052 | Train Acc: 0.9533 | Train F1: 0.9535\n",
      "Epoch: 166 | Val. Loss: 1.8077 |  Val. Acc: 0.7967 |  Val. F1: 0.7743\n",
      "Epoch: 167 | Train Loss: 0.1007 | Train Acc: 0.9568 | Train F1: 0.9568\n",
      "Epoch: 167 | Val. Loss: 1.7407 |  Val. Acc: 0.8045 |  Val. F1: 0.7867\n",
      "Epoch: 168 | Train Loss: 0.0961 | Train Acc: 0.9582 | Train F1: 0.9582\n",
      "Epoch: 168 | Val. Loss: 1.6897 |  Val. Acc: 0.8114 |  Val. F1: 0.7975\n",
      "Epoch: 169 | Train Loss: 0.0918 | Train Acc: 0.9617 | Train F1: 0.9616\n",
      "Epoch: 169 | Val. Loss: 1.6662 |  Val. Acc: 0.8163 |  Val. F1: 0.8050\n",
      "Epoch: 170 | Train Loss: 0.0876 | Train Acc: 0.9666 | Train F1: 0.9666\n",
      "Epoch: 170 | Val. Loss: 1.6652 |  Val. Acc: 0.8143 |  Val. F1: 0.8046\n",
      "Epoch: 171 | Train Loss: 0.0838 | Train Acc: 0.9690 | Train F1: 0.9690\n",
      "Epoch: 171 | Val. Loss: 1.7245 |  Val. Acc: 0.8163 |  Val. F1: 0.8070\n",
      "Epoch: 172 | Train Loss: 0.0802 | Train Acc: 0.9705 | Train F1: 0.9705\n",
      "Epoch: 172 | Val. Loss: 1.7696 |  Val. Acc: 0.8173 |  Val. F1: 0.8086\n",
      "Epoch: 173 | Train Loss: 0.0769 | Train Acc: 0.9744 | Train F1: 0.9744\n",
      "Epoch: 173 | Val. Loss: 1.7573 |  Val. Acc: 0.8143 |  Val. F1: 0.8073\n",
      "Epoch: 174 | Train Loss: 0.0741 | Train Acc: 0.9769 | Train F1: 0.9769\n",
      "Epoch: 174 | Val. Loss: 1.7697 |  Val. Acc: 0.8094 |  Val. F1: 0.8044\n",
      "Epoch: 175 | Train Loss: 0.0712 | Train Acc: 0.9784 | Train F1: 0.9784\n",
      "Epoch: 175 | Val. Loss: 1.8055 |  Val. Acc: 0.8065 |  Val. F1: 0.8020\n",
      "Epoch: 176 | Train Loss: 0.0688 | Train Acc: 0.9803 | Train F1: 0.9804\n",
      "Epoch: 176 | Val. Loss: 1.8630 |  Val. Acc: 0.8055 |  Val. F1: 0.8020\n",
      "Epoch: 177 | Train Loss: 0.0660 | Train Acc: 0.9818 | Train F1: 0.9818\n",
      "Epoch: 177 | Val. Loss: 1.8714 |  Val. Acc: 0.8006 |  Val. F1: 0.8000\n",
      "Epoch: 178 | Train Loss: 0.0643 | Train Acc: 0.9823 | Train F1: 0.9823\n",
      "Epoch: 178 | Val. Loss: 1.9377 |  Val. Acc: 0.8006 |  Val. F1: 0.8000\n",
      "Epoch: 179 | Train Loss: 0.0620 | Train Acc: 0.9838 | Train F1: 0.9838\n",
      "Epoch: 179 | Val. Loss: 2.0040 |  Val. Acc: 0.7986 |  Val. F1: 0.7988\n",
      "Epoch: 180 | Train Loss: 0.0597 | Train Acc: 0.9867 | Train F1: 0.9867\n",
      "Epoch: 180 | Val. Loss: 2.0542 |  Val. Acc: 0.7947 |  Val. F1: 0.7957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181 | Train Loss: 0.0582 | Train Acc: 0.9857 | Train F1: 0.9857\n",
      "Epoch: 181 | Val. Loss: 2.0838 |  Val. Acc: 0.7937 |  Val. F1: 0.7961\n",
      "Epoch: 182 | Train Loss: 0.0571 | Train Acc: 0.9862 | Train F1: 0.9862\n",
      "Epoch: 182 | Val. Loss: 2.1685 |  Val. Acc: 0.7917 |  Val. F1: 0.7938\n",
      "Epoch: 183 | Train Loss: 0.0548 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 183 | Val. Loss: 2.2215 |  Val. Acc: 0.7917 |  Val. F1: 0.7950\n",
      "Epoch: 184 | Train Loss: 0.0536 | Train Acc: 0.9877 | Train F1: 0.9877\n",
      "Epoch: 184 | Val. Loss: 2.2822 |  Val. Acc: 0.7898 |  Val. F1: 0.7934\n",
      "Epoch: 185 | Train Loss: 0.0521 | Train Acc: 0.9907 | Train F1: 0.9907\n",
      "Epoch: 185 | Val. Loss: 2.3578 |  Val. Acc: 0.7888 |  Val. F1: 0.7927\n",
      "Epoch: 186 | Train Loss: 0.0508 | Train Acc: 0.9902 | Train F1: 0.9902\n",
      "Epoch: 186 | Val. Loss: 2.4100 |  Val. Acc: 0.7819 |  Val. F1: 0.7882\n",
      "Epoch: 187 | Train Loss: 0.0496 | Train Acc: 0.9902 | Train F1: 0.9902\n",
      "Epoch: 187 | Val. Loss: 2.4709 |  Val. Acc: 0.7809 |  Val. F1: 0.7874\n",
      "Epoch: 188 | Train Loss: 0.0485 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 188 | Val. Loss: 2.5267 |  Val. Acc: 0.7750 |  Val. F1: 0.7833\n",
      "Epoch: 189 | Train Loss: 0.0476 | Train Acc: 0.9892 | Train F1: 0.9892\n",
      "Epoch: 189 | Val. Loss: 2.6126 |  Val. Acc: 0.7721 |  Val. F1: 0.7811\n",
      "Epoch: 190 | Train Loss: 0.0465 | Train Acc: 0.9912 | Train F1: 0.9912\n",
      "Epoch: 190 | Val. Loss: 2.6848 |  Val. Acc: 0.7721 |  Val. F1: 0.7820\n",
      "Epoch: 191 | Train Loss: 0.0454 | Train Acc: 0.9907 | Train F1: 0.9907\n",
      "Epoch: 191 | Val. Loss: 2.7359 |  Val. Acc: 0.7711 |  Val. F1: 0.7812\n",
      "Epoch: 192 | Train Loss: 0.0445 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 192 | Val. Loss: 2.8086 |  Val. Acc: 0.7682 |  Val. F1: 0.7790\n",
      "Epoch: 193 | Train Loss: 0.0433 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 193 | Val. Loss: 2.8759 |  Val. Acc: 0.7672 |  Val. F1: 0.7791\n",
      "Epoch: 194 | Train Loss: 0.0427 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 194 | Val. Loss: 2.9296 |  Val. Acc: 0.7682 |  Val. F1: 0.7803\n",
      "Epoch: 195 | Train Loss: 0.0421 | Train Acc: 0.9912 | Train F1: 0.9911\n",
      "Epoch: 195 | Val. Loss: 2.9725 |  Val. Acc: 0.7662 |  Val. F1: 0.7780\n",
      "Epoch: 196 | Train Loss: 0.0408 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 196 | Val. Loss: 3.0619 |  Val. Acc: 0.7682 |  Val. F1: 0.7803\n",
      "Epoch: 197 | Train Loss: 0.0404 | Train Acc: 0.9902 | Train F1: 0.9902\n",
      "Epoch: 197 | Val. Loss: 3.1094 |  Val. Acc: 0.7672 |  Val. F1: 0.7795\n",
      "Epoch: 198 | Train Loss: 0.0398 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 198 | Val. Loss: 3.1700 |  Val. Acc: 0.7652 |  Val. F1: 0.7781\n",
      "Epoch: 199 | Train Loss: 0.0387 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 199 | Val. Loss: 3.2382 |  Val. Acc: 0.7652 |  Val. F1: 0.7781\n",
      "Epoch: 200 | Train Loss: 0.0381 | Train Acc: 0.9907 | Train F1: 0.9906\n",
      "Epoch: 200 | Val. Loss: 3.2772 |  Val. Acc: 0.7652 |  Val. F1: 0.7781\n",
      "Epoch: 201 | Train Loss: 0.0375 | Train Acc: 0.9912 | Train F1: 0.9911\n",
      "Epoch: 201 | Val. Loss: 3.3529 |  Val. Acc: 0.7652 |  Val. F1: 0.7781\n",
      "Epoch: 202 | Train Loss: 0.0368 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 202 | Val. Loss: 3.3900 |  Val. Acc: 0.7672 |  Val. F1: 0.7804\n",
      "Epoch: 203 | Train Loss: 0.0363 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 203 | Val. Loss: 3.4334 |  Val. Acc: 0.7662 |  Val. F1: 0.7792\n",
      "Epoch: 204 | Train Loss: 0.0359 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 204 | Val. Loss: 3.4827 |  Val. Acc: 0.7672 |  Val. F1: 0.7808\n",
      "Epoch: 205 | Train Loss: 0.0353 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 205 | Val. Loss: 3.5207 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 206 | Train Loss: 0.0347 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 206 | Val. Loss: 3.5753 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 207 | Train Loss: 0.0339 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 207 | Val. Loss: 3.6042 |  Val. Acc: 0.7672 |  Val. F1: 0.7808\n",
      "Epoch: 208 | Train Loss: 0.0335 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 208 | Val. Loss: 3.6360 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 209 | Train Loss: 0.0329 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 209 | Val. Loss: 3.6662 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 210 | Train Loss: 0.0325 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 210 | Val. Loss: 3.7107 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 211 | Train Loss: 0.0321 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 211 | Val. Loss: 3.7447 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 212 | Train Loss: 0.0318 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 212 | Val. Loss: 3.7804 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 213 | Train Loss: 0.0314 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 213 | Val. Loss: 3.8250 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 214 | Train Loss: 0.0306 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 214 | Val. Loss: 3.8470 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 215 | Train Loss: 0.0301 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 215 | Val. Loss: 3.8806 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 216 | Train Loss: 0.0299 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 216 | Val. Loss: 3.9253 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 217 | Train Loss: 0.0295 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 217 | Val. Loss: 3.9803 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 218 | Train Loss: 0.0292 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 218 | Val. Loss: 4.0142 |  Val. Acc: 0.7662 |  Val. F1: 0.7800\n",
      "Epoch: 219 | Train Loss: 0.0289 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 219 | Val. Loss: 4.0681 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 220 | Train Loss: 0.0286 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 220 | Val. Loss: 4.0991 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 221 | Train Loss: 0.0282 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 221 | Val. Loss: 4.1297 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 222 | Train Loss: 0.0280 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 222 | Val. Loss: 4.1717 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 223 | Train Loss: 0.0277 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 223 | Val. Loss: 4.1993 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 224 | Train Loss: 0.0275 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 224 | Val. Loss: 4.2316 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 225 | Train Loss: 0.0272 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 225 | Val. Loss: 4.2825 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 226 | Train Loss: 0.0269 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 226 | Val. Loss: 4.3248 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 227 | Train Loss: 0.0266 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 227 | Val. Loss: 4.3563 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 228 | Train Loss: 0.0263 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 228 | Val. Loss: 4.3967 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 229 | Train Loss: 0.0261 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 229 | Val. Loss: 4.4247 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 230 | Train Loss: 0.0258 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 230 | Val. Loss: 4.4616 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 231 | Train Loss: 0.0257 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 231 | Val. Loss: 4.4925 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 232 | Train Loss: 0.0254 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 232 | Val. Loss: 4.5176 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 233 | Train Loss: 0.0252 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 233 | Val. Loss: 4.5475 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 234 | Train Loss: 0.0250 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 234 | Val. Loss: 4.5706 |  Val. Acc: 0.7652 |  Val. F1: 0.7797\n",
      "Epoch: 235 | Train Loss: 0.0249 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 235 | Val. Loss: 4.6024 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 236 | Train Loss: 0.0246 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 236 | Val. Loss: 4.6421 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 237 | Train Loss: 0.0242 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 237 | Val. Loss: 4.6684 |  Val. Acc: 0.7642 |  Val. F1: 0.7786\n",
      "Epoch: 238 | Train Loss: 0.0243 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 238 | Val. Loss: 4.7088 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 239 | Train Loss: 0.0239 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 239 | Val. Loss: 4.7351 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 | Train Loss: 0.0238 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 240 | Val. Loss: 4.7736 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 241 | Train Loss: 0.0236 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 241 | Val. Loss: 4.8004 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 242 | Train Loss: 0.0234 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 242 | Val. Loss: 4.8346 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 243 | Train Loss: 0.0233 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 243 | Val. Loss: 4.8874 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 244 | Train Loss: 0.0231 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 244 | Val. Loss: 4.9131 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 245 | Train Loss: 0.0230 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 245 | Val. Loss: 4.9393 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 246 | Train Loss: 0.0228 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 246 | Val. Loss: 4.9615 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 247 | Train Loss: 0.0227 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 247 | Val. Loss: 4.9904 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 248 | Train Loss: 0.0225 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 248 | Val. Loss: 5.0188 |  Val. Acc: 0.7633 |  Val. F1: 0.7783\n",
      "Epoch: 249 | Train Loss: 0.0224 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 249 | Val. Loss: 5.0425 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 250 | Train Loss: 0.0222 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 250 | Val. Loss: 5.0747 |  Val. Acc: 0.7652 |  Val. F1: 0.7809\n",
      "Epoch: 251 | Train Loss: 0.0222 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 251 | Val. Loss: 5.1061 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 252 | Train Loss: 0.0220 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 252 | Val. Loss: 5.1318 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 253 | Train Loss: 0.0219 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 253 | Val. Loss: 5.1626 |  Val. Acc: 0.7642 |  Val. F1: 0.7790\n",
      "Epoch: 254 | Train Loss: 0.0217 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 254 | Val. Loss: 5.1791 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 255 | Train Loss: 0.0217 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 255 | Val. Loss: 5.2125 |  Val. Acc: 0.7633 |  Val. F1: 0.7783\n",
      "Epoch: 256 | Train Loss: 0.0215 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 256 | Val. Loss: 5.2476 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 257 | Train Loss: 0.0215 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 257 | Val. Loss: 5.2657 |  Val. Acc: 0.7633 |  Val. F1: 0.7783\n",
      "Epoch: 258 | Train Loss: 0.0213 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 258 | Val. Loss: 5.2939 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 259 | Train Loss: 0.0212 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 259 | Val. Loss: 5.3256 |  Val. Acc: 0.7633 |  Val. F1: 0.7783\n",
      "Epoch: 260 | Train Loss: 0.0210 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 260 | Val. Loss: 5.3505 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 261 | Train Loss: 0.0210 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 261 | Val. Loss: 5.3810 |  Val. Acc: 0.7623 |  Val. F1: 0.7776\n",
      "Epoch: 262 | Train Loss: 0.0207 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 262 | Val. Loss: 5.3925 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 263 | Train Loss: 0.0208 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 263 | Val. Loss: 5.4237 |  Val. Acc: 0.7613 |  Val. F1: 0.7769\n",
      "Epoch: 264 | Train Loss: 0.0206 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 264 | Val. Loss: 5.4486 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 265 | Train Loss: 0.0206 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 265 | Val. Loss: 5.4807 |  Val. Acc: 0.7613 |  Val. F1: 0.7769\n",
      "Epoch: 266 | Train Loss: 0.0203 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 266 | Val. Loss: 5.5039 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 267 | Train Loss: 0.0204 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 267 | Val. Loss: 5.5314 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 268 | Train Loss: 0.0201 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 268 | Val. Loss: 5.5453 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 269 | Train Loss: 0.0202 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 269 | Val. Loss: 5.5865 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 270 | Train Loss: 0.0199 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 270 | Val. Loss: 5.5969 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 271 | Train Loss: 0.0200 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 271 | Val. Loss: 5.6270 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 272 | Train Loss: 0.0198 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 272 | Val. Loss: 5.6366 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 273 | Train Loss: 0.0198 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 273 | Val. Loss: 5.6685 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 274 | Train Loss: 0.0196 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 274 | Val. Loss: 5.6793 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 275 | Train Loss: 0.0196 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 275 | Val. Loss: 5.7224 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 276 | Train Loss: 0.0194 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 276 | Val. Loss: 5.7297 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 277 | Train Loss: 0.0195 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 277 | Val. Loss: 5.7606 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 278 | Train Loss: 0.0193 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 278 | Val. Loss: 5.7636 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 279 | Train Loss: 0.0194 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 279 | Val. Loss: 5.7993 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 280 | Train Loss: 0.0192 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 280 | Val. Loss: 5.8138 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 281 | Train Loss: 0.0192 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 281 | Val. Loss: 5.8358 |  Val. Acc: 0.7623 |  Val. F1: 0.7780\n",
      "Epoch: 282 | Train Loss: 0.0193 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 282 | Val. Loss: 5.8285 |  Val. Acc: 0.7642 |  Val. F1: 0.7802\n",
      "Epoch: 283 | Train Loss: 0.0188 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 283 | Val. Loss: 5.8523 |  Val. Acc: 0.7633 |  Val. F1: 0.7795\n",
      "Epoch: 284 | Train Loss: 0.0187 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 284 | Val. Loss: 5.8890 |  Val. Acc: 0.7633 |  Val. F1: 0.7795\n",
      "Epoch: 285 | Train Loss: 0.0186 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 285 | Val. Loss: 5.9083 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 286 | Train Loss: 0.0186 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 286 | Val. Loss: 5.9501 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 287 | Train Loss: 0.0185 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 287 | Val. Loss: 5.9640 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 288 | Train Loss: 0.0185 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 288 | Val. Loss: 5.9883 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 289 | Train Loss: 0.0184 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 289 | Val. Loss: 5.9993 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 290 | Train Loss: 0.0184 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 290 | Val. Loss: 6.0250 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 291 | Train Loss: 0.0182 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 291 | Val. Loss: 6.0566 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 292 | Train Loss: 0.0182 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 292 | Val. Loss: 6.0639 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 293 | Train Loss: 0.0185 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 293 | Val. Loss: 6.0722 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 294 | Train Loss: 0.0180 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 294 | Val. Loss: 6.1035 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 295 | Train Loss: 0.0180 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 295 | Val. Loss: 6.1241 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 296 | Train Loss: 0.0178 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 296 | Val. Loss: 6.1417 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 297 | Train Loss: 0.0179 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 297 | Val. Loss: 6.1731 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 298 | Train Loss: 0.0182 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 298 | Val. Loss: 6.1556 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 299 | Train Loss: 0.0177 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 299 | Val. Loss: 6.1868 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 300 | Train Loss: 0.0177 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 300 | Val. Loss: 6.2195 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 301 | Train Loss: 0.0175 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 301 | Val. Loss: 6.2522 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 302 | Train Loss: 0.0176 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 302 | Val. Loss: 6.2771 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 303 | Train Loss: 0.0175 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 303 | Val. Loss: 6.2883 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 304 | Train Loss: 0.0179 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 304 | Val. Loss: 6.2859 |  Val. Acc: 0.7613 |  Val. F1: 0.7777\n",
      "Epoch: 305 | Train Loss: 0.0174 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 305 | Val. Loss: 6.2994 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 306 | Train Loss: 0.0175 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 306 | Val. Loss: 6.3242 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 307 | Train Loss: 0.0172 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 307 | Val. Loss: 6.3409 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 308 | Train Loss: 0.0173 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 308 | Val. Loss: 6.3813 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 309 | Train Loss: 0.0175 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 309 | Val. Loss: 6.3788 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 310 | Train Loss: 0.0171 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 310 | Val. Loss: 6.3938 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 311 | Train Loss: 0.0170 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 311 | Val. Loss: 6.4195 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 312 | Train Loss: 0.0173 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 312 | Val. Loss: 6.4272 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 313 | Train Loss: 0.0168 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 313 | Val. Loss: 6.4323 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 314 | Train Loss: 0.0170 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 314 | Val. Loss: 6.4661 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 315 | Train Loss: 0.0168 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 315 | Val. Loss: 6.4704 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 316 | Train Loss: 0.0168 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 316 | Val. Loss: 6.4978 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 317 | Train Loss: 0.0167 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 317 | Val. Loss: 6.5154 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 318 | Train Loss: 0.0172 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 318 | Val. Loss: 6.5277 |  Val. Acc: 0.7633 |  Val. F1: 0.7795\n",
      "Epoch: 319 | Train Loss: 0.0166 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 319 | Val. Loss: 6.5275 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 320 | Train Loss: 0.0168 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 320 | Val. Loss: 6.5628 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 321 | Train Loss: 0.0168 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 321 | Val. Loss: 6.5552 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 322 | Train Loss: 0.0165 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 322 | Val. Loss: 6.5846 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 323 | Train Loss: 0.0165 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 323 | Val. Loss: 6.6068 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 324 | Train Loss: 0.0164 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 324 | Val. Loss: 6.6194 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 325 | Train Loss: 0.0164 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 325 | Val. Loss: 6.6386 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 326 | Train Loss: 0.0168 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 326 | Val. Loss: 6.6390 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 327 | Train Loss: 0.0162 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 327 | Val. Loss: 6.6532 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 328 | Train Loss: 0.0163 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 328 | Val. Loss: 6.6833 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 329 | Train Loss: 0.0161 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 329 | Val. Loss: 6.7021 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 330 | Train Loss: 0.0162 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 330 | Val. Loss: 6.7249 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 331 | Train Loss: 0.0165 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 331 | Val. Loss: 6.7206 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 332 | Train Loss: 0.0160 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 332 | Val. Loss: 6.7350 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 333 | Train Loss: 0.0161 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 333 | Val. Loss: 6.7653 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 334 | Train Loss: 0.0159 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 334 | Val. Loss: 6.7707 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 335 | Train Loss: 0.0160 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 335 | Val. Loss: 6.7920 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 336 | Train Loss: 0.0164 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 336 | Val. Loss: 6.7909 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 337 | Train Loss: 0.0158 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 337 | Val. Loss: 6.8028 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 338 | Train Loss: 0.0160 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 338 | Val. Loss: 6.8323 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 339 | Train Loss: 0.0161 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 339 | Val. Loss: 6.8363 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 340 | Train Loss: 0.0156 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 340 | Val. Loss: 6.8431 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 341 | Train Loss: 0.0158 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 341 | Val. Loss: 6.8686 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 342 | Train Loss: 0.0156 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 342 | Val. Loss: 6.8769 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 343 | Train Loss: 0.0157 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 343 | Val. Loss: 6.8968 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 344 | Train Loss: 0.0161 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 344 | Val. Loss: 6.9065 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 345 | Train Loss: 0.0155 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 345 | Val. Loss: 6.9057 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 346 | Train Loss: 0.0157 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 346 | Val. Loss: 6.9370 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 347 | Train Loss: 0.0154 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 347 | Val. Loss: 6.9416 |  Val. Acc: 0.7603 |  Val. F1: 0.7778\n",
      "Epoch: 348 | Train Loss: 0.0156 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 348 | Val. Loss: 6.9632 |  Val. Acc: 0.7613 |  Val. F1: 0.7781\n",
      "Epoch: 349 | Train Loss: 0.0159 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 349 | Val. Loss: 6.9699 |  Val. Acc: 0.7623 |  Val. F1: 0.7788\n",
      "Epoch: 350 | Train Loss: 0.0154 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 350 | Val. Loss: 6.9712 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 351 | Train Loss: 0.0156 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 351 | Val. Loss: 6.9997 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 352 | Train Loss: 0.0158 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 352 | Val. Loss: 7.0034 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 353 | Train Loss: 0.0152 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 353 | Val. Loss: 7.0116 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 354 | Train Loss: 0.0153 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 354 | Val. Loss: 7.0353 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 355 | Train Loss: 0.0152 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 355 | Val. Loss: 7.0453 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 356 | Train Loss: 0.0153 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 356 | Val. Loss: 7.0619 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 357 | Train Loss: 0.0157 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 357 | Val. Loss: 7.0705 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 358 | Train Loss: 0.0151 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 358 | Val. Loss: 7.0727 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 359 | Train Loss: 0.0153 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 359 | Val. Loss: 7.0980 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 360 | Train Loss: 0.0155 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 360 | Val. Loss: 7.1031 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 361 | Train Loss: 0.0149 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 361 | Val. Loss: 7.1097 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 362 | Train Loss: 0.0151 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 362 | Val. Loss: 7.1325 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 363 | Train Loss: 0.0149 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 363 | Val. Loss: 7.1539 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 364 | Train Loss: 0.0150 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 364 | Val. Loss: 7.1583 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 365 | Train Loss: 0.0155 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 365 | Val. Loss: 7.1675 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 366 | Train Loss: 0.0148 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 366 | Val. Loss: 7.1678 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 367 | Train Loss: 0.0150 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 367 | Val. Loss: 7.1936 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 368 | Train Loss: 0.0153 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 368 | Val. Loss: 7.1986 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 369 | Train Loss: 0.0147 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 369 | Val. Loss: 7.2065 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 370 | Train Loss: 0.0149 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 370 | Val. Loss: 7.2265 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 371 | Train Loss: 0.0147 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 371 | Val. Loss: 7.2478 |  Val. Acc: 0.7623 |  Val. F1: 0.7796\n",
      "Epoch: 372 | Train Loss: 0.0148 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 372 | Val. Loss: 7.2623 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 373 | Train Loss: 0.0153 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 373 | Val. Loss: 7.2607 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 374 | Train Loss: 0.0146 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 374 | Val. Loss: 7.2698 |  Val. Acc: 0.7623 |  Val. F1: 0.7796\n",
      "Epoch: 375 | Train Loss: 0.0149 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 375 | Val. Loss: 7.2849 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 376 | Train Loss: 0.0151 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 376 | Val. Loss: 7.2878 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 377 | Train Loss: 0.0145 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 377 | Val. Loss: 7.3073 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 378 | Train Loss: 0.0147 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 378 | Val. Loss: 7.3164 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 379 | Train Loss: 0.0145 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 379 | Val. Loss: 7.3382 |  Val. Acc: 0.7613 |  Val. F1: 0.7785\n",
      "Epoch: 380 | Train Loss: 0.0146 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 380 | Val. Loss: 7.3512 |  Val. Acc: 0.7623 |  Val. F1: 0.7796\n",
      "Epoch: 381 | Train Loss: 0.0151 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 381 | Val. Loss: 7.3495 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 382 | Train Loss: 0.0143 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 382 | Val. Loss: 7.3577 |  Val. Acc: 0.7623 |  Val. F1: 0.7796\n",
      "Epoch: 383 | Train Loss: 0.0147 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 383 | Val. Loss: 7.3224 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 384 | Train Loss: 0.0149 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 384 | Val. Loss: 7.3150 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 385 | Train Loss: 0.0143 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 385 | Val. Loss: 7.3332 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 386 | Train Loss: 0.0145 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 386 | Val. Loss: 7.3508 |  Val. Acc: 0.7623 |  Val. F1: 0.7792\n",
      "Epoch: 387 | Train Loss: 0.0144 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 387 | Val. Loss: 7.3624 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 388 | Train Loss: 0.0144 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 388 | Val. Loss: 7.3742 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 389 | Train Loss: 0.0150 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 389 | Val. Loss: 7.3718 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 390 | Train Loss: 0.0143 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 390 | Val. Loss: 7.3783 |  Val. Acc: 0.7623 |  Val. F1: 0.7796\n",
      "Epoch: 391 | Train Loss: 0.0145 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "Epoch: 391 | Val. Loss: 7.3428 |  Val. Acc: 0.7633 |  Val. F1: 0.7799\n",
      "Epoch: 392 | Train Loss: 0.0147 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 392 | Val. Loss: 7.3333 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 393 | Train Loss: 0.0141 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 393 | Val. Loss: 7.3525 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 394 | Train Loss: 0.0144 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 394 | Val. Loss: 7.3092 |  Val. Acc: 0.7642 |  Val. F1: 0.7810\n",
      "Epoch: 395 | Train Loss: 0.0142 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 395 | Val. Loss: 7.3194 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 396 | Train Loss: 0.0143 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 396 | Val. Loss: 7.3309 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 397 | Train Loss: 0.0142 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 397 | Val. Loss: 7.3404 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 398 | Train Loss: 0.0143 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 398 | Val. Loss: 7.3494 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 399 | Train Loss: 0.0142 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 399 | Val. Loss: 7.3620 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 400 | Train Loss: 0.0148 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 400 | Val. Loss: 7.3656 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 401 | Train Loss: 0.0140 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 401 | Val. Loss: 7.3697 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 402 | Train Loss: 0.0143 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 402 | Val. Loss: 7.3897 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 403 | Train Loss: 0.0146 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 403 | Val. Loss: 7.3919 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 404 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 404 | Val. Loss: 7.3998 |  Val. Acc: 0.7642 |  Val. F1: 0.7810\n",
      "Epoch: 405 | Train Loss: 0.0141 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 405 | Val. Loss: 7.4169 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 406 | Train Loss: 0.0140 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 406 | Val. Loss: 7.4242 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 407 | Train Loss: 0.0141 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 407 | Val. Loss: 7.4369 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 408 | Train Loss: 0.0146 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 408 | Val. Loss: 7.4408 |  Val. Acc: 0.7642 |  Val. F1: 0.7806\n",
      "Epoch: 409 | Train Loss: 0.0138 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 409 | Val. Loss: 7.4443 |  Val. Acc: 0.7642 |  Val. F1: 0.7810\n",
      "Epoch: 410 | Train Loss: 0.0142 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 410 | Val. Loss: 7.4618 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 411 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 411 | Val. Loss: 7.4701 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 412 | Train Loss: 0.0140 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 412 | Val. Loss: 7.4812 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 413 | Train Loss: 0.0140 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 413 | Val. Loss: 7.4902 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 414 | Train Loss: 0.0140 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 414 | Val. Loss: 7.4981 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 415 | Train Loss: 0.0146 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 415 | Val. Loss: 7.4430 |  Val. Acc: 0.7652 |  Val. F1: 0.7813\n",
      "Epoch: 416 | Train Loss: 0.0138 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 416 | Val. Loss: 7.4445 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 417 | Train Loss: 0.0141 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 417 | Val. Loss: 7.4660 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 418 | Train Loss: 0.0144 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 418 | Val. Loss: 7.4651 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 419 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 419 | Val. Loss: 7.4760 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 420 | Train Loss: 0.0139 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "Epoch: 420 | Val. Loss: 7.4304 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 421 | Train Loss: 0.0138 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 421 | Val. Loss: 7.4373 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 422 | Train Loss: 0.0138 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 422 | Val. Loss: 7.4483 |  Val. Acc: 0.7642 |  Val. F1: 0.7810\n",
      "Epoch: 423 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 423 | Val. Loss: 7.4546 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 424 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 424 | Val. Loss: 7.4635 |  Val. Acc: 0.7633 |  Val. F1: 0.7803\n",
      "Epoch: 425 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 425 | Val. Loss: 7.4701 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 426 | Train Loss: 0.0139 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 426 | Val. Loss: 7.4811 |  Val. Acc: 0.7642 |  Val. F1: 0.7810\n",
      "Epoch: 427 | Train Loss: 0.0145 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 427 | Val. Loss: 7.4827 |  Val. Acc: 0.7662 |  Val. F1: 0.7824\n",
      "Epoch: 428 | Train Loss: 0.0136 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 428 | Val. Loss: 7.4874 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 429 | Train Loss: 0.0138 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 429 | Val. Loss: 7.5075 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 430 | Train Loss: 0.0143 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 430 | Val. Loss: 7.5051 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 431 | Train Loss: 0.0136 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 431 | Val. Loss: 7.5177 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 432 | Train Loss: 0.0137 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "Epoch: 432 | Val. Loss: 7.3542 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 433 | Train Loss: 0.0136 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 433 | Val. Loss: 7.4183 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 434 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 434 | Val. Loss: 7.3690 |  Val. Acc: 0.7652 |  Val. F1: 0.7817\n",
      "Epoch: 435 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 435 | Val. Loss: 7.3723 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 436 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 436 | Val. Loss: 7.3809 |  Val. Acc: 0.7652 |  Val. F1: 0.7821\n",
      "Epoch: 437 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 437 | Val. Loss: 7.3880 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 438 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 438 | Val. Loss: 7.3946 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 439 | Train Loss: 0.0138 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 439 | Val. Loss: 7.4028 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 440 | Train Loss: 0.0137 | Train Acc: 0.9956 | Train F1: 0.9956\n",
      "Epoch: 440 | Val. Loss: 7.4097 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 441 | Train Loss: 0.0138 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 441 | Val. Loss: 7.2996 |  Val. Acc: 0.7652 |  Val. F1: 0.7821\n",
      "Epoch: 442 | Train Loss: 0.0142 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 442 | Val. Loss: 7.2953 |  Val. Acc: 0.7662 |  Val. F1: 0.7824\n",
      "Epoch: 443 | Train Loss: 0.0137 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 443 | Val. Loss: 7.3055 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 444 | Train Loss: 0.0136 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "Epoch: 444 | Val. Loss: 7.3193 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 445 | Train Loss: 0.0138 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 445 | Val. Loss: 7.3257 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 446 | Train Loss: 0.0135 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "Epoch: 446 | Val. Loss: 7.3369 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 447 | Train Loss: 0.0137 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 447 | Val. Loss: 7.3409 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 448 | Train Loss: 0.0135 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 448 | Val. Loss: 7.3477 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 449 | Train Loss: 0.0138 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 449 | Val. Loss: 7.3526 |  Val. Acc: 0.7652 |  Val. F1: 0.7821\n",
      "Epoch: 450 | Train Loss: 0.0136 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 450 | Val. Loss: 7.3599 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 451 | Train Loss: 0.0139 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 451 | Val. Loss: 7.3886 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 452 | Train Loss: 0.0136 | Train Acc: 0.9951 | Train F1: 0.9951\n",
      "Epoch: 452 | Val. Loss: 7.3711 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 453 | Train Loss: 0.0138 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 453 | Val. Loss: 7.3791 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 454 | Train Loss: 0.0137 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 454 | Val. Loss: 7.4060 |  Val. Acc: 0.7642 |  Val. F1: 0.7814\n",
      "Epoch: 455 | Train Loss: 0.0138 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 455 | Val. Loss: 7.3940 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 456 | Train Loss: 0.0138 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 456 | Val. Loss: 7.4213 |  Val. Acc: 0.7652 |  Val. F1: 0.7821\n",
      "Epoch: 457 | Train Loss: 0.0137 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 457 | Val. Loss: 7.4081 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 458 | Train Loss: 0.0138 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 458 | Val. Loss: 7.4334 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 459 | Train Loss: 0.0138 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 459 | Val. Loss: 7.4210 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 460 | Train Loss: 0.0138 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 460 | Val. Loss: 7.4455 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 461 | Train Loss: 0.0138 | Train Acc: 0.9946 | Train F1: 0.9946\n",
      "Epoch: 461 | Val. Loss: 7.4302 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 462 | Train Loss: 0.0139 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 462 | Val. Loss: 7.4551 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 463 | Train Loss: 0.0139 | Train Acc: 0.9941 | Train F1: 0.9941\n",
      "Epoch: 463 | Val. Loss: 7.3192 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 464 | Train Loss: 0.0140 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 464 | Val. Loss: 7.3433 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 465 | Train Loss: 0.0140 | Train Acc: 0.9936 | Train F1: 0.9936\n",
      "Epoch: 465 | Val. Loss: 7.2706 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 466 | Train Loss: 0.0141 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 466 | Val. Loss: 7.2930 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 467 | Train Loss: 0.0141 | Train Acc: 0.9931 | Train F1: 0.9931\n",
      "Epoch: 467 | Val. Loss: 7.2774 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 468 | Train Loss: 0.0142 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 468 | Val. Loss: 7.3019 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 469 | Train Loss: 0.0143 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 469 | Val. Loss: 7.3069 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 470 | Train Loss: 0.0144 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 470 | Val. Loss: 7.3106 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 471 | Train Loss: 0.0145 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 471 | Val. Loss: 7.3108 |  Val. Acc: 0.7652 |  Val. F1: 0.7825\n",
      "Epoch: 472 | Train Loss: 0.0146 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 472 | Val. Loss: 7.3086 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 473 | Train Loss: 0.0146 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 473 | Val. Loss: 7.3172 |  Val. Acc: 0.7652 |  Val. F1: 0.7825\n",
      "Epoch: 474 | Train Loss: 0.0148 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 474 | Val. Loss: 7.2531 |  Val. Acc: 0.7662 |  Val. F1: 0.7828\n",
      "Epoch: 475 | Train Loss: 0.0149 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 475 | Val. Loss: 7.3237 |  Val. Acc: 0.7672 |  Val. F1: 0.7840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 476 | Train Loss: 0.0151 | Train Acc: 0.9926 | Train F1: 0.9926\n",
      "Epoch: 476 | Val. Loss: 7.2670 |  Val. Acc: 0.7672 |  Val. F1: 0.7840\n",
      "Epoch: 477 | Train Loss: 0.0153 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 477 | Val. Loss: 7.2675 |  Val. Acc: 0.7662 |  Val. F1: 0.7832\n",
      "Epoch: 478 | Train Loss: 0.0155 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 478 | Val. Loss: 7.2674 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 479 | Train Loss: 0.0158 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 479 | Val. Loss: 7.2699 |  Val. Acc: 0.7662 |  Val. F1: 0.7832\n",
      "Epoch: 480 | Train Loss: 0.0159 | Train Acc: 0.9921 | Train F1: 0.9921\n",
      "Epoch: 480 | Val. Loss: 7.2923 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 481 | Train Loss: 0.0161 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 481 | Val. Loss: 7.2713 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 482 | Train Loss: 0.0165 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 482 | Val. Loss: 7.3025 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 483 | Train Loss: 0.0168 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 483 | Val. Loss: 7.3009 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 484 | Train Loss: 0.0176 | Train Acc: 0.9912 | Train F1: 0.9912\n",
      "Epoch: 484 | Val. Loss: 7.3103 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 485 | Train Loss: 0.0169 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 485 | Val. Loss: 7.3137 |  Val. Acc: 0.7662 |  Val. F1: 0.7836\n",
      "Epoch: 486 | Train Loss: 0.0178 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 486 | Val. Loss: 7.3859 |  Val. Acc: 0.7652 |  Val. F1: 0.7833\n",
      "Epoch: 487 | Train Loss: 0.0180 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 487 | Val. Loss: 7.4330 |  Val. Acc: 0.7642 |  Val. F1: 0.7826\n",
      "Epoch: 488 | Train Loss: 0.0179 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 488 | Val. Loss: 7.3850 |  Val. Acc: 0.7642 |  Val. F1: 0.7826\n",
      "Epoch: 489 | Train Loss: 0.0184 | Train Acc: 0.9916 | Train F1: 0.9916\n",
      "Epoch: 489 | Val. Loss: 7.3432 |  Val. Acc: 0.7652 |  Val. F1: 0.7833\n",
      "Epoch: 490 | Train Loss: 0.0188 | Train Acc: 0.9902 | Train F1: 0.9902\n",
      "Epoch: 490 | Val. Loss: 7.3625 |  Val. Acc: 0.7652 |  Val. F1: 0.7833\n",
      "Epoch: 491 | Train Loss: 0.0195 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 491 | Val. Loss: 7.3937 |  Val. Acc: 0.7642 |  Val. F1: 0.7826\n",
      "Epoch: 492 | Train Loss: 0.0200 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 492 | Val. Loss: 7.3517 |  Val. Acc: 0.7652 |  Val. F1: 0.7833\n",
      "Epoch: 493 | Train Loss: 0.0204 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 493 | Val. Loss: 7.3892 |  Val. Acc: 0.7642 |  Val. F1: 0.7826\n",
      "Epoch: 494 | Train Loss: 0.0214 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 494 | Val. Loss: 7.3861 |  Val. Acc: 0.7652 |  Val. F1: 0.7837\n",
      "Epoch: 495 | Train Loss: 0.0225 | Train Acc: 0.9897 | Train F1: 0.9897\n",
      "Epoch: 495 | Val. Loss: 7.4656 |  Val. Acc: 0.7642 |  Val. F1: 0.7830\n",
      "Epoch: 496 | Train Loss: 0.0228 | Train Acc: 0.9887 | Train F1: 0.9887\n",
      "Epoch: 496 | Val. Loss: 7.4585 |  Val. Acc: 0.7633 |  Val. F1: 0.7823\n",
      "Epoch: 497 | Train Loss: 0.0245 | Train Acc: 0.9882 | Train F1: 0.9882\n",
      "Epoch: 497 | Val. Loss: 7.5257 |  Val. Acc: 0.7633 |  Val. F1: 0.7823\n",
      "Epoch: 498 | Train Loss: 0.0257 | Train Acc: 0.9877 | Train F1: 0.9877\n",
      "Epoch: 498 | Val. Loss: 7.5338 |  Val. Acc: 0.7633 |  Val. F1: 0.7823\n",
      "Epoch: 499 | Train Loss: 0.0269 | Train Acc: 0.9867 | Train F1: 0.9867\n",
      "Epoch: 499 | Val. Loss: 7.5300 |  Val. Acc: 0.7633 |  Val. F1: 0.7823\n",
      "Best Val. F1: 0.8086, Best Val. Accuarcy: 0.8173\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.005)\n",
    "criterion = nn.BCELoss()\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_f1 = -float('inf')\n",
    "best_model = None\n",
    "best_acc = -float('inf')\n",
    "\n",
    "for epoch in range(500):\n",
    "\n",
    "    train_loss, train_acc, train_f1 = train(model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc, val_f1 = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_model = copy.deepcopy(model)\n",
    "        best_acc = valid_acc\n",
    "\n",
    "    print(f'Epoch: {epoch} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}')\n",
    "    print(f'Epoch: {epoch} | Val. Loss: {valid_loss:.4f} |  Val. Acc: {valid_acc:.4f} |  Val. F1: {val_f1:.4f}')\n",
    "\n",
    "print(\"Best Val. F1: {:.4f}, Best Val. Accuarcy: {:.4f}\".format(best_f1, best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"synthetic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_query = torch.from_numpy(query_x)\n",
    "XX_val = torch.from_numpy(val_x)\n",
    "XX_test = torch.from_numpy(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    yy_query_p = torch.round(model(XX_query)).numpy()\n",
    "    yy_val_p = torch.round(model(XX_val)).numpy()\n",
    "    yy_test_p = torch.round(model(XX_test)).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32,  4.42],\n",
       "       [ 1.92,  2.32],\n",
       "       [ 2.62,  0.92],\n",
       "       ...,\n",
       "       [-0.28,  3.92],\n",
       "       [ 1.42,  2.22],\n",
       "       [ 2.92,  5.52]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dquery[:, 0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddquery = np.concatenate((dquery[:, 0:2], yy_query_p), axis = 1)\n",
    "ddval = np.concatenate((dval[:, 0:2], yy_val_p), axis = 1)\n",
    "ddtest = np.concatenate((dtest[:, 0:2], yy_test_p), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"synthetic_query_v1.npy\", ddquery)\n",
    "np.save(\"synthetic_val_v1.npy\", ddval)\n",
    "np.save(\"synthetic_test_v1.npy\", ddtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(yy_query_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.32  4.42]\n",
      " [ 1.92  2.32]\n",
      " [ 2.62  0.92]\n",
      " ...\n",
      " [-0.28  3.92]\n",
      " [ 1.42  2.22]\n",
      " [ 2.92  5.52]]\n"
     ]
    }
   ],
   "source": [
    "print(dquery[:, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611\n"
     ]
    }
   ],
   "source": [
    "print(len(dquery))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
